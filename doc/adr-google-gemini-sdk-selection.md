# ADR: Google Gemini SDKの選択 - @ai-sdk/google vs @google/generative-ai

## ステータス
承認済み (2025-04-23)

## コンテキスト
DeepResearch機能にGoogle Geminiモデルのサポートを追加する必要がある。このための実装方法として以下の2つの選択肢がある：

1. **既存の`ai-sdk/google`プロバイダーを活用する**
   - Vercel AI SDKのプロバイダーとしてすでにシステムに統合されている
   - 他のAI提供者と統一されたインターフェース

2. **`@google/generative-ai`を直接使用する新しいプロバイダーを追加する**
   - GoogleによるGemini APIの公式JavaScriptクライアント
   - 直接Gemini APIにアクセスするシンプルな実装

## 決定
**既存の`ai-sdk/google`プロバイダーを使用してGoogle Geminiモデルにアクセスする。**

## 根拠

### 「既存の`ai-sdk/google`を使用する」選択の利点
1. **一貫性**: 他のLLMプロバイダーもすべて`ai-sdk/*`パッケージを使用している
2. **保守性**: 新しいプロバイダー型や設定を追加する必要がなく、メンテナンスが容易
3. **インターフェースの統一性**: AI SDKの抽象化を通じて統一されたインターフェースを維持できる
4. **既に統合済み**: 環境変数`GOOGLE_GENERATIVE_AI_API_KEY`も設定済みである

### 「`@google/generative-ai`を直接使用する」選択の欠点
1. **重複**: 同じサービスに対して複数のアクセス方法が存在することになる
2. **保守の複雑性**: 新しいプロバイダーのメンテナンスが必要になる
3. **新しい依存関係**: 別のパッケージとその依存関係を追加する必要がある
4. **環境変数の複製**: 新たな環境変数（`GOOGLE_AI_API_KEY`）を追加する必要がある

## 影響
1. **コード変更**: 追加のプロバイダーやパッケージのインポートを行わない
2. **設定**: 既存の環境変数設定を継続して使用
3. **ドキュメント**: DeepResearch実装・拡張ガイドに`ai-sdk/google`プロバイダーを使用してGeminiモデルにアクセスする方法を記載

## オプション
以下のGeminiモデルが利用可能：

### Gemini 2.0シリーズ
- **gemini-2.0-pro**: 高度な推論タスク向けの最新モデル
- **gemini-2.0-flash**: レイテンシの低い高速モデル
- **gemini-2.0-pro-vision**: 画像理解特化モデル

### Gemini 1.5シリーズ
- **gemini-1.5-pro**: 100万トークンのコンテキストをサポートするモデル
- **gemini-1.5-flash**: 効率的な応答のための軽量モデル

## 備考
将来的にGemini APIが大幅に変更された場合や、ai-sdkがGeminiの新機能をサポートしなくなった場合は、この決定を再検討する必要がある。
